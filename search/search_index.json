{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kubernetes Documentation","text":""},{"location":"#acknowledgment","title":"\ud83d\udcda Acknowledgment","text":"<ul> <li> <p>This guide is based on lecture materials provided by Imran Teli, my technology instructor.</p> </li> <li> <p>\ud83e\uddd1\u200d\ud83c\udfeb By Alexander Lindholm \u2014 Beta Version</p> </li> </ul> <p></p>"},{"location":"#hello-and-welcome","title":"\ud83d\udc4b Hello and welcome!","text":"<p>\ud83d\udc77\ud83c\udffb You are currently viewing the beta version of this documentation. It is actively being developed and improved.</p> <p>\ud83d\udcd6 Use the navigation bar above to explore the available content and sections.</p>"},{"location":"cheatsheet/","title":"Kubernetes Cheat Sheet","text":"<ul> <li>Kubectl Context and Configuration</li> <li>Creating Objects</li> <li>Interacting With Nodes and Cluster</li> </ul>"},{"location":"cheatsheet/#useful-commands-to-automatically-create-yaml-configs","title":"Useful Commands to Automatically Create YAML Configs","text":""},{"location":"cheatsheet/#create-a-declarative-yaml-for-a-pod","title":"Create a Declarative YAML for a Pod","text":"<pre><code>kubectl run nginxpod --image=nginx --dry-run=client -o yaml &gt; ngpod.yaml\ncat ngpod.yaml\n</code></pre>"},{"location":"cheatsheet/#create-a-yaml-for-a-deployment","title":"Create a YAML for a Deployment","text":"<pre><code>kubectl create deployment ngdep --image=nginx --dry-run=client -o yaml &gt; ngdep.yaml\n</code></pre>"},{"location":"commands_arguments/","title":"Commands and Arguments","text":""},{"location":"commands_arguments/#cmd","title":"CMD","text":"<p>Command that will start the container process:</p> <pre><code>FROM ubuntu\nCMD echo \"Hello World\"\n</code></pre> <pre><code>FROM ubuntu\nCMD [\"/usr/bin/wc\",\"--help\"]\n</code></pre> <p>Similar to CMD but higher priority <pre><code>FROM ubuntu\nENTRYPOINT [\"executable\", \"param1\", \"param2\"]\n</code></pre></p> <p>If ENTRYPOINT and CMD are used together then the ENTRYPOINT will run first.</p> <p>Usually when used together the ENTRYPOINT would be the command and CMD the argument, Example:</p> <pre><code>FROM ubuntu\nENTRYPOINT[echo]\nCMD[\"hi\"]\n</code></pre>"},{"location":"commands_arguments/#kubernetes-example","title":"Kubernetes Example","text":"<pre><code>vim commands.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: command-demo\n  labels:\n    purpose: demonstrate-command\nspec:\n  containers:\n\n  - name: command-demo-container\n    image: debian\n    command: [\"printenv\"]\n    args: [\"HOSTNAME\", \"KUBERNETES_PORT\"]\n\n  - name: echo-demo\n    image: debian\n    env:\n      - name: MESSAGE\n        value: \"hello world\"\n    command: [\"/bin/echo\"]\n    args: [\"$(MESSAGE)\"]\n\n  restartPolicy: OnFailure\n</code></pre> <p>Note: You can only use one <code>command</code> and <code>args</code> per container. To try both examples, comment/uncomment the relevant lines or create two containers in the pod. 2 containers running is not recomended in production unless its side-container or container that will start another container.</p> <p>env: - name: MESSAGE   value: \"hello world\" command: [\"/bin/echo\"] args: [\"$(MESSAGE)\"]</p> <p>start pod</p> <pre><code>kubectl apply -f commands.yaml\nkubectl get pod\n\n# wait for status: Completed\n\nkubectl logs command-demo\n</code></pre> <p>Docs</p>"},{"location":"config_map/","title":"Config Map","text":"<p>https://kubernetes.io/docs/concepts/configuration/configmap/#using-configmaps-as-environment-variables</p>"},{"location":"config_map/#environment-variables","title":"Environment Variables","text":"<p>Pods are disposable and do not retain persistent changes.</p> <p>We can inject environment variables into a Pod at runtime.</p>"},{"location":"config_map/#example","title":"Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: env-configmap\nspec:\n  containers:\n  - name: envars-test-container\n    image: nginx\n    env:\n    - name: CONFIGMAP_USERNAME\n      valueFrom:\n        configMapKeyRef:\n          name: myconfigmap\n          key: username\n</code></pre>"},{"location":"config_map/#create-config-maps-imperative","title":"Create Config Maps - Imperative","text":"<p>https://kubernetes.io/docs/reference/kubectl/generated/kubectl_create/kubectl_create_configmap/</p> <p><pre><code>kubectl create configmap db-config --from-literal=MYSQL_DATABASE=accounts \\\n --from-literal=MYSQL_ROOT_PASSWORD=somecomplexpass\n</code></pre> <pre><code>configmap/db-config created\n</code></pre></p> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl get cm db-config -o yaml\n</code></pre> <pre><code>kubectl describe cm db-config\n</code></pre>"},{"location":"config_map/#create-config-maps-declarative","title":"Create Config Maps - Declarative","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: db-config\ndata:\n  MYSQL_ROOT_PASSWORD: somecomplexpass\n  MYSQL_DATABASE: accounts\n</code></pre> <p>Apply changes: <pre><code>kubectl create -f db-cm.yml\n</code></pre></p>"},{"location":"config_map/#pod-reading-config-maps","title":"POD Reading Config Maps","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      envFrom:\n        - configMapRef:\n            name: db-config\n      ports:\n        - name: db-port\n          containerPort: 3306\n</code></pre>"},{"location":"config_map/#select-a-key-from-a-config-map","title":"Select a Key from a Config Map","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      env:\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: db-config\n              key: DB_HOST\n      ports:\n        - name: db-port\n          containerPort: 3306\n</code></pre>"},{"location":"config_map/#hands-on","title":"Hands On","text":"<pre><code>vim samplecm.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: game-demo\ndata:\n  # property-like keys; each key maps to a simple value\n  player_initial_lives: \"3\"\n  ui_properties_file_name: \"user-interface.properties\"\n\n  # file-like keys\n  game.properties: |\n    enemy.types=aliens,monsters\n    player.maximum-lives=5    \n  user-interface.properties: |\n    color.good=purple\n    color.bad=yellow\n    allow.textmode=true\n</code></pre> <pre><code>kubectl apply -f samplecm.yaml\n</code></pre> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl get cm game-demo -o yaml\n</code></pre> <p>There are four different ways that you can use a ConfigMap to configure a container inside a Pod:</p> <ol> <li>Inside a container command and args</li> <li>Environment variables for a container</li> <li>Add a file in read-only volume, for the application to read</li> <li>Write code to run inside the Pod that uses the Kubernetes API to read a ConfigMap</li> </ol> <pre><code>vim readcmpod.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmap-demo-pod\nspec:\n  containers:\n    - name: demo\n      image: alpine\n      command: [\"sleep\", \"3600\"]\n      env:\n        # Define the environment variable\n        - name: PLAYER_INITIAL_LIVES # Notice that the case is different here\n                                     # from the key name in the ConfigMap.\n          valueFrom:\n            configMapKeyRef:\n              name: game-demo           # The ConfigMap this value comes from.\n              key: player_initial_lives # The key to fetch.\n        - name: UI_PROPERTIES_FILE_NAME\n          valueFrom:\n            configMapKeyRef:\n              name: game-demo\n              key: ui_properties_file_name\n      volumeMounts:\n      - name: config\n        mountPath: \"/config\"\n        readOnly: true\n  volumes:\n  # You set volumes at the Pod level, then mount them into containers inside that Pod\n  - name: config\n    configMap:\n      # Provide the name of the ConfigMap you want to mount.\n      name: game-demo\n      # An array of keys from the ConfigMap to create as files\n      items:\n      - key: \"game.properties\"\n        path: \"game.properties\"\n      - key: \"user-interface.properties\"\n        path: \"user-interface.properties\"\n</code></pre> <pre><code>kubectl get cm\n</code></pre> <pre><code>kubectl apply -f readcmpod.yaml\n</code></pre> <pre><code>kubectl get pod\n</code></pre> <pre><code>kubectl exec --stdin --tty configmap-demo-pod -- /bin/sh\n</code></pre> <p>Validate <pre><code>ls /config/\n</code></pre></p> <pre><code>cat /config/game.properties\n</code></pre> <pre><code>cat /config/user-interface.properties\n</code></pre> <pre><code>echo $PLAYER_INITIAL_LIVES\n</code></pre> <pre><code>echo $UI_PROPERTIES_FILE_NAME\n</code></pre>"},{"location":"daemonset/","title":"DaemonSet","text":"<p>DaemonSet</p> <p>A DaemonSet ensures that each node runs one copy of a specific Pod.</p> <p>Commonly used for log collection, monitoring agents, or storage drivers.</p> <p>DaemonSet pods can expose metrics that tools like Prometheus scrape and Grafana visualizes.</p> <p>Example DaemonSet YAML</p>"},{"location":"daemonset/#hands-on-create-a-daemonset","title":"Hands On: Create a DaemonSet","text":"<p>Copy yaml content from example above.</p> <pre><code>vim sampleds.yaml # Paste the yaml content here\n</code></pre> <pre><code>kubectl apply -f samleds.yaml\n# ................ created\n</code></pre> <p>Validate</p> <pre><code>kubectl get ds -A\n</code></pre> <pre><code># Output:\nNAMESPACE      NAME                       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR\nkube-system    ebs-csi-node                   3         3        3         3             3       kubernetes.io/os=linux\nkube-system    fluentd-elasticsearch          3         3        3         3             3       &lt;none&gt;\nkube-system    kops-controller                1         1        1         1             1       kops.k8s.io/kops-controller-pki=,node-role.kubernetes.io/master=\n</code></pre> <pre><code>kubectl get pod -n kube-system\n</code></pre> <pre><code># Output:\nNAME                                                                READY   STATUS    RESTARTS    AGE\ncoredns-7884856795-knjlw                                            1/1     Running   0           48m\ncoredns-7884856795-sclvx                                            1/1     Running   0           48m\ncoredns-autoscaler-57dd867df6-vqwjp                                 1/1     Running   0           48m\ndns-controller-5869b5468f-g44fs                                     1/1     Running   0           48m\nebs-csi-controller-58c77d6dbc-srbqn                                 6/6     Running   0           48m\nebs-csi-node-6884r                                                  3/3     Running   0           48m\nebs-csi-node-bnsf6                                                  3/3     Running   1 (47m ago) 48m\nebs-csi-node-z59c6                                                  3/3     Running   1 (47m ago) 48m\netcd-manager-events-ip-172-20-37-60.us-east-2.compute.internal      1/1     Running   0           48m\netcd-manager-main-ip-172-20-37-60.us-east-2.compute.internal        1/1     Running   0           48m\n**fluentd-elasticsearch-2mdqt**                                     1/1     Running   0           41s\n**fluentd-elasticsearch-fbwb4**                                     1/1     Running   0           41s\n**fluentd-elasticsearch-jsnh8**                                     1/1     Running   0           41s\nkops-controller-w5rsl                                               1/1     Running   0           48m\nkube-apiserver-ip-172-20-37-60.us-east-2.compute.internal           2/2     Running   0           49m\nkube-controller-manager-ip-172-20-37-60.us-east-2.compute.internal  1/1     Running   0           49m\nkube-proxy-ip-172-20-37-60.us-east-2.compute.internal               1/1     Running   0           48m\nkube-proxy-ip-172-20-48-52.us-east-2.compute.internal               1/1     Running   0           47m\nkube-proxy-ip-172-20-77-191.us-east-2.compute.internal              1/1     Running   0           46m\nkube-scheduler-ip-172-20-37-60.us-east-2.compute.internal           1/1     Running   0           48m\n</code></pre>"},{"location":"deployment/","title":"Deployment","text":"<p>Upgrade your apps (pod images).</p> <p>Rollbacks if something goes wrong.</p> <p>A deployment controller provides declarative updates for Pods and ReplicaSets (Deployment creates ReplicaSet to manage number of PODS).</p> <p>You describe a desired state in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate.</p>"},{"location":"deployment/#update-image-tag","title":"Update Image Tag","text":"<p>example tags:</p> <ul> <li>nginx:1.0</li> <li>nginx:2.0</li> <li>nginx:3.0</li> </ul> <p>With deployments you can upgrade from old image tag e.g: <code>nginx:1.0</code> to <code>nginx:3.0</code>.</p> <p>If something goes wrong then the image will roll back to old version <code>nginx:1.0</code>.</p>"},{"location":"deployment/#hands-on","title":"Hands On","text":"<p><code>vim nginx-deployment.yaml</code> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\n</code></pre></p> <p>Run the deployment <pre><code>kubectl apply -y nginx-deployment.yaml\n\nkubectl get deployments\n\n# example output:\n# NAME               READY   UP-TO-DATE   AVAILABLE   AGE\n# nginx-deployment   0/3     0            0           1s\n\n\nkubectl get deploy\n\nkubectl get rs\n\nkubectl get pod\n\nkubectl describe pod &lt;pod-name&gt;\n</code></pre></p>"},{"location":"deployment/#updating-a-deployment","title":"Updating a deployment","text":"<pre><code>kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1\n</code></pre> <p>check if new version was changed: <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre></p> <p>search for <code>image:</code></p> <p>confirm that the version is set to <code>1.16.1</code></p>"},{"location":"deployment/#rollback-to-a-previous-revision","title":"Rollback to a Previous Revision","text":"<p>check if there is old revision</p> <pre><code>kubectl get rs\n</code></pre> <p>output: <pre><code>NAME                       DESIRED\nnginx-deployment-11111111  0 &lt;-- previous revision\nnginx-deployment-11111111  3\n</code></pre></p> <pre><code>kubectl rollout undo deployment/nginx-deployment\n</code></pre> <pre><code>kubectl get rs\n</code></pre> <p>output: <pre><code>NAME                       DESIRED\nnginx-deployment-11111111  0 \nnginx-deployment-11111111  3 &lt;-- previous revision\n</code></pre></p> <pre><code>kubectl get pod\nkubectl describe pod &lt;pod-name&gt; | grep Image\n</code></pre> <p>check revision rollout history <pre><code>kubectl rollout history deployment/nginx-deployment\n</code></pre></p> <p>rollout to revision number <pre><code>kubectl rollout undo deployment/nginx-deployment --to-revision=2\n</code></pre></p>"},{"location":"deployment/#delete-deployment","title":"Delete Deployment","text":"<pre><code>kubectl get deploy\n</code></pre> <pre><code>kubectl delete deploy &lt;name&gt;\n</code></pre>"},{"location":"deployment/#remember","title":"Remember","text":"<p>imperetive is for learning, testing purpose.</p> <p>But in production do it through definition files.</p>"},{"location":"deployment/#link-to-docs","title":"Link to DOCS","text":"<p>Link to Kubernetes deployment - official docs</p>"},{"location":"different_logging/","title":"Logging","text":""},{"location":"different_logging/#test-environments","title":"Test Environments","text":"<p>Before deploying to production, always verify the application in different environments:</p> <ol> <li>Test in local environment</li> <li>Test in test/dev environment</li> <li>Finally in production environment</li> </ol>"},{"location":"different_logging/#debugging-your-kubernetes-cluster","title":"Debugging Your Kubernetes Cluster","text":"<p>Mistakes and bugs can happen \u2014 be prepared to investigate and resolve them efficiently.</p>"},{"location":"different_logging/#troubleshooting-pods","title":"Troubleshooting Pods","text":"<p>List pods and their status:</p> <pre><code>kubectl get pod\nkubectl get pod -o wide\n</code></pre>"},{"location":"different_logging/#viewing-pod-logs-and-events","title":"Viewing Pod Logs and Events","text":""},{"location":"different_logging/#level-1-view-full-pod-definition","title":"Level 1: View Full Pod Definition","text":"<pre><code>kubectl get pod &lt;pod-name&gt; -o yaml\n</code></pre>"},{"location":"different_logging/#level-2-describe-the-pod-look-at-events-for-errors","title":"Level 2: Describe the pod (Look at Events for errors)","text":"<pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"different_logging/#level-3-view-pod-logs-commandsprocess-outputs","title":"Level 3: View Pod logs (commands/process outputs)","text":"<pre><code>kubectl logs &lt;pod-name&gt;\n</code></pre>"},{"location":"different_logging/#scenario-example-debugging-a-broken-image","title":"Scenario Example: Debugging a Broken Image","text":"<p>Suppose you find the following error in the logs:</p> <pre><code># Logs:\nkubelet     Pulling image \"nginax:1.15.0\"\nkubelet     Failed to pull image \"nginax:1.15.0\"\n</code></pre> <p>The issue is a misspelled image name (nginax instead of nginx). To fix it:</p>"},{"location":"different_logging/#step-1-delete-the-pod","title":"Step 1: Delete the Pod","text":"<pre><code>kubectl delete pod nginx12\n</code></pre>"},{"location":"different_logging/#step-2-edit-the-pod","title":"Step 2: Edit the Pod","text":"<pre><code># pod2.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx12\nspec:\n  containers:\n  - name: \n    image: nginx:1.15.0 # &lt;-- Corrected image name\n    ports:\n    - containerPort: 80\n</code></pre>"},{"location":"different_logging/#step-3-apply-the-updated-pod","title":"Step 3: Apply the Updated Pod","text":"<pre><code>kubectl apply -f pod2.yaml\n# output example: pod/nginx12 created\n</code></pre>"},{"location":"different_logging/#step-4-verify-the-pod-is-running","title":"Step 4: Verify the Pod is Running","text":"<pre><code>kubect get pod\n</code></pre> <p>You should see: <pre><code>nginx12 1/1 Running\n</code></pre></p>"},{"location":"eks_introduction/","title":"Amazon Elastic Kubernetes Service","text":"<p>There are ways to create and handle Kubernetes by using Kops, Kubeadm, etc.</p> <p>Problems with default k8s setup:</p> <ul> <li>Its complex to manage a Kubernetes cluster.</li> <li>This requires system administration.</li> </ul> <p>Solutions with EKS:</p> <ul> <li>Amazon EKS is an self-managed service.</li> <li>You just have to pass simple information about your cluster details.</li> <li>You can change capacity and scale it whenever you want.</li> <li>Automatically deploys Kubernetes control plane</li> </ul>"},{"location":"eks_introduction/#automation-with-eks","title":"Automation with EKS","text":"<p>Use published Terraform modules</p> <ul> <li>AWS VPC</li> <li>AWS EKS</li> </ul>"},{"location":"eks_introduction/#demo","title":"Demo","text":"<p>Clone a predefined terraform code for EKS</p> <pre><code>git clone https://github.com/hkhcoder/vprofile-project.git\n</code></pre> <pre><code>git switch terraform-eks\n</code></pre>"},{"location":"eks_introduction/#setup-and-run-terraform","title":"Setup and run Terraform","text":"<ol> <li> <p>Install Terraform</p> </li> <li> <p>Install Kubectl</p> </li> <li> <p>IAM</p> </li> <li>Create IAM user</li> <li>Premission: <code>administraitor access</code></li> <li>Security credentials: Create and Download the <code>access key</code></li> <li> <p>Type <code>aws configure</code> in terminal and paste the credentials</p> </li> <li> <p>Go to the repository you recently cloned(repository <code>vprofile-project</code>, branch <code>terraform-eks</code>)</p> </li> <li> <p>Run the following commands to create the EKS Cluster</p> </li> </ol> <pre><code>ls\n# eks-cluster.tf  main.tf  outputs.tf  terraform.tf  variables.tf  vpc.tf\n\nterraform init\n\nterraform plan\n\nterraform apply\n</code></pre> <p>We should have 3 public and 3 private VPC's.</p> <p>In total we should have 6 subnets.</p> <p>Create or update a kubeconfig file for your cluster. Replace region-code with the AWS Region that your cluster is in and replace my-cluster with the name of your cluster. <pre><code>aws eks update-kubeconfig --region region-code --name my-cluster\n</code></pre></p> <p>Test kubeconfig <pre><code>kubectl get nodes\n</code></pre></p>"},{"location":"helm_hands_on/","title":"Helm Hands On","text":""},{"location":"helm_hands_on/#wordpress-setup","title":"WordPress Setup","text":""},{"location":"helm_hands_on/#workflow-for-helm","title":"Workflow for Helm","text":"<ol> <li> <p>Create Kubernetes Definition Files </p> <ul> <li>Set up WordPress using Kubernetes objects:<ul> <li>Deployment</li> <li>Service</li> <li>Persistent Volume Claim (PVC)</li> <li>Ingress</li> <li>Secret</li> </ul> </li> </ul> </li> <li> <p>Convert to Helm </p> <ul> <li>Use AI tools to develop Helm charts efficiently.<ul> <li>Amazon Q (Generative AI)</li> </ul> </li> </ul> </li> <li> <p>Deploy and Manage </p> <ul> <li>Deploy the chart: <code>helm install &lt;release-name&gt; &lt;chart-path&gt;</code></li> <li>Upgrade the chart: <code>helm upgrade &lt;release-name&gt; &lt;chart-name&gt; -f values.yaml</code></li> <li>Uninstall the chart: <code>helm uninstall &lt;release-name&gt;</code></li> <li>List releases: <code>helm list</code></li> </ul> </li> <li> <p>More Options in Helm </p> <ul> <li>Use Code Assistant to implement Dev Best practices.</li> </ul> </li> </ol>"},{"location":"helm_hands_on/#demo","title":"Demo","text":"<p>Have kubectl on your PC</p> <p>Have a kubernetes cluster installed on your AWS EC 2 instance</p> <pre><code>kubectl get nodes\n# NAME        STATUS         ROLE\n# i-dg3       Ready          node\n# i-gha       Ready          control-plane\n# i-7df       Ready          node\n</code></pre> <p>setup ingress controller:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.2/deploy/static/provider/aws/deploy.yaml\n</code></pre> <p>Display and copy entire cubeconfig file:</p> <pre><code>cat ~/.kube/config\n</code></pre> <p>create a kubeconfig file on your PC</p> <pre><code>mkdir ~/.kube\nvim ~/.kube/config # Paste the entire cubeconfig contet here.\n</code></pre>"},{"location":"helm_hands_on/#create-a-worpress-app-mysql-db-in-helm","title":"Create a Worpress App &amp; MySQL DB in Helm","text":"<p>How?</p> <ol> <li> <p>Open a browser, find the definition files, copy paste and make changes.</p> <ol> <li>In google, search for <code>wordpress kubernetes definitions</code></li> <li>You should find a page like <code>Deploying WordPress and MySQL with Persistent Volumes</code></li> <li>Teke this resources and create files, change settings and run it</li> </ol> </li> <li> <p>Ask AmazonQ AI to create it for us.</p> <ol> <li>Install and Setup AmazonQ from VSC Extensions</li> <li>Use the prompt to create the resources/files</li> <li>AmazonQ is currently the most accurate AI for Kubernetes</li> </ol> </li> </ol>"},{"location":"helm_hands_on/#build-with-amazonq","title":"Build with AmazonQ","text":"<p>Make sure we have Nginx ingress controller: <pre><code>kubectl get ns  # NameSpaces\n# NAME              STATUS   AGE\n# default           Active   46m\n# ingress-nginx     Active   21m   &lt;---\n# kube-node-lease   Active   46m\n# kube-public       Active   46m\n# kube-system       Active   46m\n</code></pre></p> <p>Check storage class:</p> <p><pre><code>kubectl get sc # StorageClass\n</code></pre> <pre><code># OUTPUT\nNAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\ndefault                kubernetes.io/aws-ebs   Delete          Immediate              false                  47m\ngp2                    kubernetes.io/aws-ebs   Delete          Immediate              false                  47m\nkops-csi-1-21 (default) ebs.csi.aws.com        Delete          WaitForFirstConsumer   true                   47m\nkops-ssd-1-17          kubernetes.io/aws-ebs   Delete          WaitForFirstConsumer   true                   47m\n</code></pre></p> <p>As you see we have EBS type volume that was created by 'Kops' for AWS.</p> <p>So we need to mention this EBS volume type as 'Storage Class'.</p> <p>Make sure to have all the information before writing the prompt.</p>"},{"location":"helm_hands_on/#amazonq-prompt-demo","title":"AmazonQ Prompt Demo","text":"<p>Open a new foulder with VSC.</p> <p>Prompt AmazonQ this text and wait for AI to build the files.</p> <pre><code>Wordpress setup kubernetes definitions files. Separate files for wordpress app, mysql (needs to be version 8.0), app service, db service, PVC, secret and ingress. PVC should use storage class default, secret file should contain all the db users and db passwords for mysql and wordpress both. Ingress will be nginx with hostname wordpress.alexanderlindholm.net.\n</code></pre> <p>7 files should be created: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\n1 directory, 7 files\n</code></pre></p> <p>Install Helm</p> <p>Create Helm chart</p> <pre><code>helm create wp-chart\n</code></pre> <p>Additional example/template files should be created in wp-chart directory:</p> <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 deployment.yaml\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u251c\u2500\u2500 hpa.yaml\n    \u2502   \u251c\u2500\u2500 ingress.yaml\n    \u2502   \u251c\u2500\u2500 NOTES.txt\n    \u2502   \u251c\u2500\u2500 serviceaccount.yaml\n    \u2502   \u251c\u2500\u2500 service.yaml\n    \u2502   \u2514\u2500\u2500 tests\n    \u2502       \u2514\u2500\u2500 test-connection.yaml\n    \u2514\u2500\u2500 values.yaml\n\n5 directories, 17 files\n</code></pre> <p>Delete all <code>.yaml</code> files in templates directory:</p> <pre><code>rm wp-chart/templates/*.yaml\n</code></pre> <p>Delete the wp-chart directory:</p> <pre><code>rm -rf wp-chart/templates/tests/\n</code></pre> <p>Clear all text in <code>values.yaml</code>:</p> <pre><code>echo \"\" &gt; wp-chart/values.yaml\n</code></pre> <p>File structure should now look like this: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u2514\u2500\u2500 NOTES.txt\n    \u2514\u2500\u2500 values.yaml\n\n4 directories, 12 files\n</code></pre></p> <p>Copy ai created kubernetes definition files to templates directory:</p> <pre><code>cp ./* ./wp-chart/templates/\n</code></pre> <p>File Structure should now look like: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\u2514\u2500\u2500 wp-chart\n    \u251c\u2500\u2500 charts\n    \u251c\u2500\u2500 Chart.yaml\n    \u251c\u2500\u2500 templates\n    \u2502   \u251c\u2500\u2500 _helpers.tpl\n    \u2502   \u251c\u2500\u2500 mysql-deployment.yaml\n    \u2502   \u251c\u2500\u2500 mysql-pvc.yaml\n    \u2502   \u251c\u2500\u2500 mysql-service.yaml\n    \u2502   \u251c\u2500\u2500 NOTES.txt\n    \u2502   \u251c\u2500\u2500 wordpress-deployment.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-ingress.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-pvc.yaml\n    \u2502   \u251c\u2500\u2500 wordpress-secret.yaml\n    \u2502   \u2514\u2500\u2500 wordpress-service.yaml\n    \u2514\u2500\u2500 values.yaml\n\n4 directories, 20 files\n</code></pre></p> <p>in <code>mysql-deployment.yaml</code></p> <p>replace</p> <pre><code>metadata:\n  name: wordpress-mysql\n</code></pre> <p>to</p> <pre><code>metadata:\n  name: {{ include \"word-chart.fullname\" . }}-app\n</code></pre> <p>replace</p> <pre><code>image: mysql:8.0\n</code></pre> <p>to</p> <pre><code>image: {{ .Values.mysql.image.repository }}:{{ .Values.mysql.image.tag }}\n</code></pre> <p>Add values in <code>mysql-deployment.yaml</code></p> <pre><code>mysql:\n  image:\n    repository: mysql\n    tag: 8.0\n</code></pre> <p>Then to deploy the app run</p> <pre><code>helm install demo ./wp-chart\n</code></pre>"},{"location":"helm_introduction/","title":"Helm","text":""},{"location":"helm_introduction/#what-is-helm-package-manager","title":"What is Helm Package Manager?","text":"<p>Helm helps you manage your application as a single package on a Kubernetes cluster.</p> <p>To run an application, we often need to use multiple Kubernetes objects, such as:</p> <ul> <li>Deployments</li> <li>Services</li> <li>Ingress</li> <li>Backend Objects:<ul> <li>Volumes</li> <li>Secrets</li> <li>ConfigMaps</li> <li>DaemonSets</li> <li>StatefulSets</li> <li>etc.</li> </ul> </li> </ul> <p>Using Helm, we can convert these definition files into a single Helm chart.</p> <p>This means an application becomes a bundle of different objects packaged into a Helm chart, allowing us to deploy the application as a single suite.</p> <p>This means we deploy the application as a single suit.</p> <p>Helm provides commands to manage applications, such as:</p> <ul> <li><code>helm install &lt;app&gt;</code></li> <li><code>helm uninstall &lt;app&gt;</code></li> <li><code>helm upgrade &lt;app&gt;</code> (change settings or versions)</li> <li>etc.</li> </ul>"},{"location":"helm_introduction/#key-components-of-helm-in-kubernetes","title":"Key Components of Helm in Kubernetes","text":"<p>. Charts     - A package of pre-configured Kubernetes resources for applications. 2. Repositories     - Storage locations for managing and sharing Helm charts. 3. Releases     - Instances of charts running in a Kubernetes cluster. 4. Values     - Configuration settings that customize charts during deployment.</p>"},{"location":"helm_introduction/#chart-structure","title":"Chart Structure","text":"<pre><code>wordpress-chart/\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u251c\u2500\u2500 mysql-deployment.yaml\n\u2502   \u251c\u2500\u2500 mysql-service.yaml\n\u2502   \u251c\u2500\u2500 NOTES.txt\n\u2502   \u251c\u2500\u2500 persistent-volume-claims.yaml\n\u2502   \u251c\u2500\u2500 secret.yaml\n\u2502   \u251c\u2500\u2500 wordpress-deployment.yaml\n\u2502   \u251c\u2500\u2500 wordpress-service.yaml\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n</code></pre> <ol> <li> <p>Create a Chart </p> <ul> <li>Use the command: <code>helm create myapp</code></li> </ul> </li> <li> <p>Content of the Chart </p> <ul> <li>Create a <code>templates</code> folder and add <code>values.yaml</code> files.</li> </ul> </li> <li> <p>Deploy and Manage </p> <ul> <li>Deploy the chart: <code>helm install &lt;release-name&gt; &lt;chart-path&gt;</code></li> <li>Upgrade the chart: <code>helm upgrade &lt;release-name&gt; &lt;chart-name&gt; -f values.yaml</code></li> <li>Uninstall the chart: <code>helm uninstall &lt;release-name&gt;</code></li> <li>List releases: <code>helm list</code></li> </ul> </li> <li> <p>Helm Repositories </p> <ul> <li>Add a repository: <code>helm repo add bitnami https://charts.bitnami.com/bitnami</code></li> <li>Update repositories: <code>helm repo update</code></li> <li>Install a chart from a repository: <code>helm install my-nginx bitnami/nginx</code></li> </ul> </li> </ol>"},{"location":"helm_with_ai/","title":"Helm with AI","text":"<p>Prompt AmazonQ this text and wait for AI to build the files.</p> <pre><code>Wordpress setup kubernetes definitions files. Separate files for wordpress app, mysql (needs to be version 8.0), app service, db service, PVC, secret and ingress. PVC should use storage class default, secret file should contain all the db users and db passwords for mysql and wordpress both. Ingress will be nginx with hostname wordpress.alexanderlindholm.net.\n</code></pre> <p>7 files should be created: <pre><code>.\n\u251c\u2500\u2500 mysql-deployment.yaml\n\u251c\u2500\u2500 mysql-pvc.yaml\n\u251c\u2500\u2500 mysql-service.yaml\n\u251c\u2500\u2500 wordpress-deployment.yaml\n\u251c\u2500\u2500 wordpress-ingress.yaml\n\u251c\u2500\u2500 wordpress-pvc.yaml\n\u251c\u2500\u2500 wordpress-secret.yaml\n\u251c\u2500\u2500 wordpress-service.yaml\n\n1 directory, 7 files\n</code></pre></p> <p>Use AmazonQ to read definition files and create the chart for us.</p> <p>Prompt AmazonQ this text and wait for AI to built the chart.</p> <pre><code>Create helm charts from these kubernetes definitions file. Use release name in metadata. Replace other hardcoded values into variables and add those variables in values.yaml file.\n</code></pre> <p>Check the chart to make sure everything is correct.</p> <p>Lint the chart</p> <pre><code>helm lint wordpress-chart\n</code></pre> <pre><code>helm template wordpress-chart\n</code></pre> <p>if everything looks good launch Kubernetes Chart</p> <pre><code>helm install wp wordpress-chart -n wp-ns --create-namespace\n</code></pre> <p>Get namespace status</p> <pre><code>helm list -n wp-ns\n</code></pre> <p>Get all resources in <code>wp-ns</code> namespace</p> <pre><code>kubectl get all -n wp-ns\n</code></pre> <p>Check ingress status</p> <pre><code>kubectl get ingress -n wp-ns\n</code></pre> <p>Describe ingress</p> <pre><code>kubectl describe ingress -n wp-ns\n</code></pre>"},{"location":"helm_with_ai/#version","title":"Version","text":"<p>If there are new changes to the chart then the version needs to be changed:</p> <pre><code>vim Chart.yaml\n</code></pre> <pre><code>apiVersion: v2\nname: wordpress\ndescription: A Helm chart for WordPress with MySQL\ntype: application\nversion: 0.1.1 # &lt;-- Change this version\nappVersion: \"1.0.0\"\n</code></pre> <p>Upgrade the Kubernetes to use latest changes</p> <pre><code>helm upgrade wp wordpress-chart -n wp-ns\n</code></pre> <p>Get namespace status</p> <pre><code>helm list -n wp-ns\n</code></pre> <p>Get all resources in <code>wp-ns</code> namespace</p> <pre><code>kubectl get all -n wp-ns\n</code></pre>"},{"location":"helm_with_ai/#ask-ai-to-improve-the-code","title":"Ask AI to Improve the Code","text":"<p>For Example prompt AI this:</p> <pre><code>Improve helm charts as per developmental best practices.\n</code></pre>"},{"location":"history/","title":"History","text":""},{"location":"history/#google-containers-2014","title":"Google + Containers (2014)","text":"<p>At Google, everything from Search to Gmail runs inside Linux containers. By 2014, Google was launching over 2 billion container instances per week across its global data centers. The power of containers allowed Google to deliver highly reliable and efficiently scalable services.</p> <p>That same year, Google took a major step forward \u2014 making its container orchestration expertise available to the world.</p>"},{"location":"history/#kubernetes-history","title":"\ud83d\udcdc Kubernetes History","text":""},{"location":"history/#2014-the-birth-of-kubernetes","title":"\ud83d\udee0\ufe0f 2014 \u2013 The Birth of Kubernetes","text":"<p>Kubernetes was created by Google as an open-source version of its internal container orchestration system, Borg. - Mid-2014: Google announces Kubernetes to the public.</p>"},{"location":"history/#2015-official-launch","title":"\ud83d\ude80 2015 \u2013 Official Launch","text":"<ul> <li>July 21, 2015: Kubernetes v1.0 is released.  </li> <li>Google partners with the Linux Foundation to form the Cloud Native Computing Foundation (CNCF) to manage the project.</li> </ul>"},{"location":"history/#2016-kubernetes-goes-mainstream","title":"\ud83c\udf0d 2016 \u2013 Kubernetes Goes Mainstream","text":"<ul> <li>Tools like kops, Minikube, and kubeadm emerge to simplify Kubernetes adoption.  </li> <li>September 29, 2016: The Pok\u00e9mon GO case study is published, highlighting Kubernetes at scale in production.</li> </ul>"},{"location":"history/#2017-enterprise-adoption-accelerates","title":"\ud83c\udfe2 2017 \u2013 Enterprise Adoption Accelerates","text":"<ul> <li>Google and IBM announce Istio, a service mesh for Kubernetes.  </li> <li>GitHub migrates infrastructure to Kubernetes.  </li> <li>Oracle joins the CNCF as a major cloud provider.</li> </ul>"},{"location":"ingress/","title":"Ingress","text":""},{"location":"ingress/#what-is-ingress","title":"What is Ingress ?","text":"<p>Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster.</p> <pre><code>graph LR\n    client[Client] --&gt; lb[Ingress-managed Load Balancer]\n    lb --&gt; ingress[Ingress]\n    ingress --&gt; service[Service]\n    service --&gt; pod1[Pod]\n    service --&gt; pod2[Pod]</code></pre>"},{"location":"ingress/#prerequisites","title":"Prerequisites","text":"<p>You must have an Ingress controller to satisfy an Ingress. Only creating an Ingress resource has no effect.</p> <p>Ingress Controllers List</p> <ul> <li>AKS Application Gateway Ingress Controller</li> <li>Apache APISIX ingress controller</li> <li>Avi Kubernetes Operator</li> <li>NGINX Ingress Controller for Kubernetes</li> <li>And many many more</li> </ul>"},{"location":"ingress/#hands-on-install-nginx-ingress","title":"Hands On: Install Nginx Ingress","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.3/deploy/static/provider/aws/deploy.yaml\n</code></pre> <pre><code>kubectl get ns\n# ingress-nginx    Active    12s\n</code></pre> <pre><code>kubectl get all -n ingress-nginx\n</code></pre> <pre><code>NAME                                           READY   STATUS      RESTARTS   AGE\npod/ingress-nginx-admission-create-12345       0/1     Completed   0          23s\npod/ingress-nginx-admission-patch-12345        0/1     Completed   1          23s\npod/ingress-nginx-controller-69fbbf9f9c-h67pr  0/1     Running     0          23s\nNAME                                        TYPE           CLUSTER-IP       EXTERNAL-IP                                                      PORT(S)                       AGE\nservice/ingress-nginx-controller            LoadBalancer   100.68.173.127   a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com   80:32718/TCP, 443:32372/TCP   23s\nservice/ingress-nginx-controller-admission  ClusterIP      100.66.154.8     &lt;none&gt;                                                           443/TCP                       23s\n\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/ingress-nginx-controller    1/1     1            1           23s\n\nNAME                                                  DESIRED   CURRENT   READY   AGE\nreplicaset.apps/ingress-nginx-controller-69fbfbf9f9c  1         1         1    23s\n\nNAME                                           COMPLETIONS   DURATION   AGE\njob.batch/ingress-nginx-admission-create       1/1           3s         23s\njob.batch/ingress-nginx-admission-patch        1/1           4s         23s\n</code></pre> <p>In this example the credentials are:</p> <ul> <li>External DNS (Load Balancer): <ul> <li><code>a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code></li> </ul> </li> <li>Internal IP (Load Balancer): <code>100.68.173.127</code></li> <li>Internal IP (Cluster IP): <code>100.66.154.8</code></li> <li>Ingress routing (following your defined rules): <ul> <li><code>pod/ingress-nginx-controller-69fbbf9f9c-h67pr</code></li> </ul> </li> <li>Deployment: <code>deployment.apps/ingress-nginx-controller</code></li> <li>Replica set: <code>replicaset.apps/ingress-nginx-controller-69fbfbf9f9c</code></li> <li>Jobs:<ul> <li><code>job.batch/ingress-nginx-admission-create</code></li> <li><code>job.batch/ingress-nginx-admission-patch</code></li> </ul> </li> </ul> <p>This commands will create a loadbalancer in ROUTE 53 (AWS Cloud)</p> <p><pre><code>vim vprodep.yaml\n</code></pre> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  selector:\n    matchLabels:\n      run: my-app\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        run: my-app\n    spec:\n      containers:\n        - name: my-app\n          image: imranvisualpath/vproappfix\n          ports:\n            - containerPort: 8080\n</code></pre></p> <pre><code>vim vprosvc.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app\nspec:\n  ports:\n    - port: 8080\n      protocol: TCP\n      targetPort: 8080\n  selector:\n    run: my-app\n  type: ClusterIP\n</code></pre> <pre><code>vim vproingress.yaml\n</code></pre> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: vpro-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: vprofile.alexanderlindholm.net\n      http:\n        paths:\n          - path: /login\n            pathType: Prefix\n            backend:\n              service:\n                name: my-app\n                port:\n                  number: 8080\n</code></pre> <p>replace <code>alexanderlindholm.net</code> with your DNS name</p> <pre><code>kubectl apply -f vprodep.yaml\n</code></pre> <pre><code>kubectl apply -f vprosvc.yaml\n</code></pre> <p>Create DNS CNAME before Applying <code>vproingress.yaml</code></p> <p>Visit your DNS provider, in my case it will be Namecheap</p> <ol> <li> <p>Go to DNS records section (Advanced DNS for Namecheap)</p> </li> <li> <p>Apply this credentials:</p> <ul> <li><code>TYPE: CNAME</code></li> <li><code>Name: vprofile</code></li> <li><code>Value: a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code></li> </ul> </li> </ol> <p>Check if my-app service is running:</p> <pre><code>kubectl get svc\n# my-app    ClusterIP    100.69.158.126    &lt;none&gt;    8080/TCP    120s\nkubectl describe svc my-app\n</code></pre> <p>Keep in mind that we are creating Ingress rule for this ClusterIP Service</p> <ol> <li>Client makes an HTTP request to: http://vprofile.alexanderlindholm.net/login (This DNS name resolves to the External IP/DNS of the Ingress LoadBalancer.)</li> <li>The request hits the Ingress Controller (NGINX) via the LoadBalancer, which processes the request using the rules defined in your Ingress resource. It then forwards the request to the my-app Service (which is of type ClusterIP).</li> <li>The ClusterIP Service (my-app) routes the traffic to one of the backing Pods (using label selectors), and the application running in the pod responds.</li> </ol> <pre><code>graph LR\n    client[\"Client (vprofile.alexanderlindholm.net/login)\"] --&gt; lb[\"LoadBalancer (Ingress Controller)\"]\n    lb --&gt; ingress[\"Ingress Resource: /login\"]\n    ingress --&gt; service[\"ClusterIP Service: my-app\"]\n    service --&gt; pod[\"Pod: my-app\"]</code></pre> <pre><code>kubectl apply -f vproingress.yaml\n</code></pre> <pre><code>kubectl get ingress\n# vpro-ingress   nginx   vprofile.alexanderlindholm.net   a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com\n</code></pre> <p>Visit page at: <code>a07bff36074ee45d6a8ab27eb91b1f83-f.elb.us-west-2.amazonaws.com</code>.</p> <p>This URL would be different for you.</p> <pre><code>kubectl delete ingress vpro-ingress\n</code></pre>"},{"location":"ingress/#optional-change-app-path-to-fix-content-rendering-on-the-page","title":"Optional: Change app path to fix content rendering on the page","text":"<p>The page is not rendering becouse the routing is happening internally not in the app</p> <pre><code>vim vproingress.yaml\n# change /login to /\n</code></pre> <pre><code>kubectl apply -f vproingress.yaml &amp;&amp; kubectl get ingress --watch\n</code></pre>"},{"location":"ingress/#delete","title":"Delete","text":"<pre><code>kubectl get ns\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.3/deploy/static/provider/aws/deploy.yaml\n</code></pre>"},{"location":"introduction/","title":"Introduction to Kubernetes?","text":"<p>If the Docker Engine fails, all containers running on that engine will go down, making them inaccessible to users.</p> <p>This is where Kubernetes comes in \u2014 it manages multiple Docker Engines, known as Docker nodes, within a Kubernetes cluster. This setup ensures high availability and fault tolerance.</p> <p></p> <p>For example, if a container on the third node fails, Kubernetes automatically reschedules and migrates that container to a healthy node in the cluster.</p>"},{"location":"introduction/#container-orchestration","title":"\ud83e\udde0 Container Orchestration","text":"<p>Container orchestration refers to managing the deployment, scaling, networking, and availability of containers across a cluster of Docker/worker nodes.</p> <p>In Kubernetes, these nodes form a single pool of compute resources that is fault-tolerant and self-healing.</p>"},{"location":"introduction/#popular-container-orchestration-tools","title":"\ud83d\udd27 Popular Container Orchestration Tools","text":"<ul> <li>Docker Swarm</li> <li>Kubernetes \ud83c\udf1f</li> <li>Mesosphere Marathon</li> <li>AWS ECS &amp; EKS</li> <li>Azure Container Service</li> <li>Google Kubernetes Engine (GKE)</li> <li>CoreOS Fleet</li> <li>OpenShift</li> </ul>"},{"location":"introduction/#what-kubernetes-provides","title":"\ud83d\ude80 What Kubernetes Provides","text":"<ul> <li> <p>Service Discovery &amp; Load Balancing   Automatically exposes containers using DNS names or IPs and distributes traffic across them.</p> </li> <li> <p>Storage Orchestration   Mounts persistent storage from local disks or cloud providers like:</p> </li> <li>SAN (Storage Area Network)</li> <li>NAS (Network Attached Storage)</li> <li>AWS EBS volumes</li> <li> <p>Ceph</p> </li> <li> <p>Automated Rollouts &amp; Rollbacks   Gradually updates applications and rolls back if something goes wrong.</p> </li> <li> <p>Automatic Bin Packing   Places containers based on resource requirements and availability to maximize efficiency.</p> </li> <li> <p>Self-Healing   Automatically restarts failed containers, replaces unresponsive nodes, and kills misbehaving containers.</p> </li> <li> <p>Secrets &amp; Configuration Management   Manages sensitive data like passwords, SSH keys, and environment variables securely and separately from your application code.</p> </li> </ul>"},{"location":"introduction/#kubernetes-architecture","title":"\ud83d\udcca Kubernetes Architecture","text":"<p>link to model</p>"},{"location":"introduction/#components","title":"\ud83c\udf9b Components","text":""},{"location":"introduction/#master-component-kube-api-server","title":"\ud83e\udde0 Master Component: Kube API Server","text":"<ul> <li>Acts as the central communication hub for all Kubernetes components.</li> <li>Exposes the Kubernetes API, making it the frontend of the control plane.</li> <li>Handles all external and internal requests, including scheduling, deployments, and health checks.</li> <li>Admins interact with it via the <code>[kubectl](https://kubernetes.io/docs/reference/kubectl/)</code> CLI or through automated systems.</li> <li>A web-based dashboard can be integrated using the API.</li> <li>Enables integration with third-party tools and services like CI/CD, monitoring, and more.</li> </ul>"},{"location":"introduction/#master-etcd-server","title":"\ud83d\udcbe Master: etcd Server","text":"<ul> <li>Stores all cluster data for the Kubernetes control plane.</li> <li>A consistent and highly available key-value store that serves as Kubernetes' backing store.</li> <li>The Kube API Server retrieves and writes data to etcd.</li> <li>It should be backed up regularly to ensure disaster recovery.</li> <li>Maintains the current state of all objects in the cluster (nodes, pods, configs, etc.).</li> </ul>"},{"location":"introduction/#master-kube-scheduler","title":"\ud83d\udce6 Master: Kube Scheduler","text":"<ul> <li>Monitors newly created pods that do not yet have an assigned node.</li> <li>Selects the most suitable node for each pod to run on.</li> <li>Key factors considered during scheduling include:</li> <li>Resource requirements (CPU, memory)</li> <li>Hardware/software/policy constraints</li> <li>Affinity and anti-affinity rules</li> <li>Data locality</li> <li>Inter-workload interference</li> <li>Deadlines and priorities</li> </ul>"},{"location":"introduction/#master-controller-manager","title":"\ud83e\udde9 Master: Controller Manager","text":"<p>Logically, each controller is a separate process. However, to reduce complexity, they are all compiled into a single binary and run in a single process: the kube-controller-manager.</p> <p>These controllers include:</p> <ul> <li> <p>Node Controller   Detects and responds when nodes become unresponsive or go offline.</p> </li> <li> <p>Replication Controller   Ensures the correct number of pod replicas are running for each replication controller object in the cluster.</p> </li> <li> <p>Endpoint Controller   Populates the <code>Endpoints</code> object, connecting Services to their corresponding Pods.</p> </li> <li> <p>Service Account &amp; Token Controller   Automatically creates default service accounts and API tokens for newly created namespaces.</p> </li> </ul>"},{"location":"introduction/#node-components","title":"\ud83e\uddf1 Node Components","text":""},{"location":"introduction/#kubelet","title":"\ud83d\udccc Kubelet","text":"<ul> <li>An agent that runs on every node in the cluster.</li> <li>Ensures that the containers described in the PodSpec are running and healthy.</li> <li>Communicates with the Kube API Server to receive instructions and report status.</li> </ul>"},{"location":"introduction/#kube-proxy","title":"\ud83c\udf10 Kube Proxy","text":"<ul> <li>A network proxy that also runs on each node in the cluster.</li> <li>Maintains network rules on nodes, allowing:</li> <li>Communication between Pods within the cluster</li> <li>External access to Services from outside the cluster</li> <li>Handles TCP/UDP forwarding and supports virtual IPs via iptables or IPVS.</li> </ul>"},{"location":"introduction/#container-runtime","title":"\ud83d\udd27 Container Runtime","text":"<ul> <li>The software responsible for running containers on each node.</li> <li>Kubernetes supports multiple container runtimes via the Container Runtime Interface (CRI), including:</li> <li>Docker</li> <li>containerd</li> <li>CRI-O</li> <li>rktlet (now deprecated)</li> </ul>"},{"location":"introduction/#pods","title":"\ud83d\udce6 PODS","text":"<p>(Reference: Imran Teli)</p> <p> </p>"},{"location":"introduction/#addons","title":"\ud83e\udde9 Addons","text":"<p>Kubernetes supports a variety of addons that extend its core functionality:</p> <ul> <li> <p>DNS   Provides name resolution for services and pods within the cluster.</p> </li> <li> <p>Web UI (Dashboard)   A web-based interface for managing and visualizing the cluster.</p> </li> <li> <p>Container Resource Monitoring   Tracks usage metrics like CPU, memory, and disk for containers.</p> </li> <li> <p>Cluster-Level Logging   Collects and stores logs from all cluster components for debugging and auditing.</p> </li> </ul>"},{"location":"introduction/#kubernetes-setup-tools","title":"\u2699\ufe0f Kubernetes Setup Tools","text":""},{"location":"introduction/#the-hard-way-manual-setup","title":"\ud83d\udee0\ufe0f The Hard Way (Manual Setup)","text":"<ul> <li>Full manual installation of Kubernetes components (used for learning and deep understanding).</li> <li>Requires setting up etcd, API server, controller manager, scheduler, kubelet, and kube-proxy manually.</li> </ul>"},{"location":"introduction/#minikube","title":"\ud83e\uddea Minikube","text":"<ul> <li>Creates a single-node Kubernetes cluster on your local machine.</li> <li>Great for testing, development, and learning.</li> </ul>"},{"location":"introduction/#kubeadm","title":"\u26a1 Kubeadm","text":"<ul> <li>Tool to easily set up multi-node Kubernetes clusters.</li> <li>Platform-agnostic: works on VMs, EC2 instances, physical machines, and more.</li> <li>Handles essential steps like initializing the cluster and joining nodes.</li> </ul>"},{"location":"introduction/#kops","title":"\u2601\ufe0f Kops","text":"<ul> <li>Used for deploying production-grade multi-node Kubernetes clusters on AWS.</li> <li>Supports HA (High Availability) setups, upgrades, and more.</li> </ul>"},{"location":"introduction/#whats-next","title":"\ud83d\udcd8 What's Next?","text":"<ul> <li>Kubernetes History</li> <li>Setup kubernetes on Raspberry PI</li> </ul>"},{"location":"jobs_cron_jobs/","title":"Jobs and Cron Jobs","text":""},{"location":"jobs_cron_jobs/#jobs","title":"Jobs","text":"<p>A Job runs a task to completion \u2014 once or multiple times, depending on settings.</p> <p>They temporarily run as pods on nodes to handle specific tasks.</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n      - name: pi\n        image: perl:5.34.0\n        command: [\"perl\",  \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\n      restartPolicy: Never\n  backoffLimit: 4\n</code></pre>"},{"location":"jobs_cron_jobs/#cronjob","title":"CronJob","text":"<p>A CronJob runs Jobs on a schedule, like a Linux cron job. Each run creates a Pod that executes the task.</p> <p>They temporarily run as pods on nodes to handle specific tasks.</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"* * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox:1.28\n            imagePullPolicy: IfNotPresent\n            command:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"kube_config/","title":"What is Kube Config File?","text":"<p>The kubeconfig file is a configuration file used by <code>kubectl</code> to access Kubernetes clusters. By default, it is located at <code>~/.kube/config</code></p>"},{"location":"kube_config/#the-kubeconfig-file-organizes-information-about","title":"The Kubeconfig File Organizes Information About:","text":"<ol> <li>Cluster \u2013 API server addresses and associated settings</li> <li>Users \u2013 Credentials and authentication information</li> <li>Namespaces \u2013 Default namespace for kubectl commands (A namespace in Kubernetes is a way to divide cluster resources between multiple users or applications.)</li> <li>Authentication mechanisms \u2013 How users authenticate with clusters</li> </ol>"},{"location":"kube_config/#kubeconfig-example","title":"kubeconfig example","text":"<pre><code>apiVersion: v1\nkind: Config\n\nproxy-url: https://proxy.host:3128\n\nclusters:\n- cluster:\n    proxy-url: http://proxy.example.org:3128\n    server: https://k8s.example.org/k8s/clusters/c-xxyyzz\n  name: development\n\nusers:\n- name: developer\n\ncontexts:\n- context:\n    cluster: development\n    user: developer\n  name: development\n\ncurrent-context: development\n</code></pre> <p>The contexts section maps a cluster to a user, allowing <code>ubectl</code> to know which credentials to use for which cluster.</p> <p>The current-context defines which context is used by default when running <code>kubectl</code> commands.</p> <p>If you have <code>kubectl</code> installed on another machine, you can copy the kubeconfig file to that machine to access the same Kubernetes cluster from both.</p> <p><code>current-context</code> </p> <p>if you have cubectl installed on another machine and you can copy cubeconfig file to that machine then you can talk to api master node from both machines </p> <p>Find more information see the official kubeconfig docs.</p>"},{"location":"kubernetes_infrastructure_diagram/","title":"Kubernetes architecture diagram","text":""},{"location":"kubernetes_infrastructure_diagram/#kubernetes-infrastructure-diagram","title":"Kubernetes Infrastructure Diagram","text":"<p>CLICK ME to view the diagram in Excalidraw</p> <p></p>"},{"location":"lens/","title":"Lens","text":""},{"location":"lens/#what-is-lens","title":"What is Lens ?","text":"<p>Lens is a central tool used to visualize data for all your Kubernetes clusters.</p>"},{"location":"lens/#setting-up-lens","title":"Setting up Lens","text":"<ol> <li> <p>Install Lens from here.</p> </li> <li> <p>Open the application.</p> </li> <li> <p>Open your kubeconfig:</p> <ul> <li>Navigate to <code>home</code> directory \u2192 <code>KUBERNETES CLUSTERS</code> \u2192 <code>Local Kubeconfigs</code> \u2192 <code>+ Add Kubeconfig</code></li> </ul> </li> </ol> <p>Right-click on the cluster name to access shortcuts to <code>Settings</code> and more.</p> <p>Lens requires a Prometheus scraping tool to display and visualize data as graphs.</p> <p>Enable metrics in <code>Settings</code> \u2192 <code>Lens Metrics</code></p>"},{"location":"limits/","title":"Limits","text":""},{"location":"limits/#limits","title":"Limits","text":"<p>Use limits to set the minimum and maximum amount of CPU, RAM, etc.</p> <pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: frontend\nspec:\n  containers:\n  - name: app\n    image: images.my-company.example/app:v4\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n  - name: log-aggregator\n    image: images.my-company.example/log-aggregator:v6\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n</code></pre>"},{"location":"namespaces/","title":"Namespaces","text":"<p>Namespaces lets you isolate group of resources within a single cluster.</p>"},{"location":"namespaces/#default-kubernetes-namespace","title":"Default Kubernetes Namespace","text":"<p>These namespaces gets created automatically when a cluster is created:</p> <ul> <li>default</li> <li>kube-system</li> <li>kube-public</li> <li>kube-node-lease</li> </ul> <p>Get namespaces: <code>kubectl get namespaces</code></p>"},{"location":"namespaces/#cli-commands","title":"CLI Commands","text":"<p>Get all objects in default namespace: <code>kubectl get all</code></p> <p>Show all resources from all namespaces: <code>kubectl get all-  namespaces</code></p> <p>Services from a specific namespace: <code>kubectl svc -n kube-system</code></p> <p>Create namespace: <code>kubectl create ns kubekart</code></p> <p>And run a pod: <code>kubectl run nginx1 --image=nginx -n kubekart</code></p> <p>Get pod from your namespace: <code>kubectl get podf -n kubekart</code></p> <p>Delete a namespace: <code>kubectl delete ns kubekart</code></p>"},{"location":"namespaces/#specify-namespace-in-definition-file","title":"Specify Namespace in Definition File:","text":"<pre><code>cat pod1.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx12\n  namespace: kubekart\n  labels:\n    app: frontend\n    project: infinity\nspec:\n  containers:\n    - name: httpd-container\n      image: httpd\n      imagePullPolicy: IfNotPresent\n      ports:\n        - name: http-port\n          containerPort: 8080 # exposed port\n</code></pre> <p><code>kubectl apply -f pod1.yaml</code></p> <p>Extra namespaces example:</p> <ul> <li>dev</li> <li>prod</li> </ul>"},{"location":"namespaces/#change-prefered-namespace-in-kubeconfig-file","title":"Change prefered namespace in kubeconfig file","text":"<pre><code>kubectl config set-context --current --namespace=&lt;insert-namespace-name-here&gt;\n# Validate\nkubectl config view --minify | grep namespace:\n</code></pre>"},{"location":"objects/","title":"Objects in K8S","text":""},{"location":"objects/#pod","title":"Pod","text":"<ul> <li>The smallest deployable unit in Kubernetes.</li> <li>Represent a single instance of running processes in your cluster</li> <li>Can contain one or more containers that share storage and network</li> <li>Pods that run a single container<ul> <li>The \"one-container-per-pod\" model is the most common Kubernetes use case (Kubernetes manages the Pods rather than the containers directly).</li> </ul> </li> <li>Multi Container POD<ul> <li>Tightly coupled and need to share resources</li> <li>One main container and other as sidecar or init container (or both)</li> <li>Each Pod is meant to run a single instance of a given application</li> <li>Should use multiple Pods to scale horizontally</li> </ul> </li> </ul> <p>Definitions file in example similar to docker compose / docker run. <code>pod-setup.yml</code> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: webapp-pod\n  labels:\n    app: frontend\n    project: infinity\nspec:\n  containers:\n    - name: httpd-container\n      image: httpd\n      imagePullPolicy: IfNotPresent\n      ports:\n        - name: http-port\n          containerPort: 8080 # exposed port\n</code></pre></p> <p>Then to create the pod run this command:  <pre><code>kubectl create -f pod-setup.yml\n</code></pre></p> <p>Use commands below to get info</p> <pre><code>kubectl get pod\nkubectl describe pod webapp-pod\nkubectl get pod webapp-pod -o yaml\nkubectl get pod webapp-pod -o yaml &gt; webpod-definition.yml\n</code></pre> <p>Edit pod webapp-pod</p> <pre><code>kubectl edit webapp-pod\n</code></pre> <p>Type of Kind:</p> Kind API Version Pod v1 Service v1 Deployment apps/v1 Ingress networking.k8s.io/v1 <p>Pods docs</p>"},{"location":"objects/#service","title":"Service","text":"<ul> <li>Provides a stable network endpoint to access Pods.</li> <li>Supports different types: ClusterIP (default), NodePort, LoadBalancer, and ExternalName.</li> <li>Enables load balancing across multiple Pod replicas.</li> </ul>"},{"location":"objects/#replica-set","title":"Replica Set","text":"<ul> <li>Ensures a specified number of Pod replicas are running at any given time.</li> <li>Automatically replaces failed or terminated Pods to maintain the desired count.</li> </ul>"},{"location":"objects/#deployment","title":"Deployment","text":"<ul> <li>Provides declarative updates for Pods and ReplicaSets.</li> <li>Manages rollouts and rollbacks of application versions.</li> <li>Supports updating container images via image tags.</li> </ul>"},{"location":"objects/#config-map","title":"Config Map","text":"<ul> <li>Stores non-sensitive configuration data as key-value pairs.</li> <li>Used to decouple configuration artifacts from application code.</li> <li>Can inject data into Pods as environment variables, command-line arguments, or configuration files.</li> </ul>"},{"location":"objects/#secret","title":"Secret","text":"<ul> <li>Stores sensitive data (e.g., passwords, tokens, SSH keys) in base64-encoded format.</li> <li>Prevents exposing sensitive information in plain text.</li> <li>Can be mounted as files or exposed as environment variables in Pods.</li> </ul>"},{"location":"objects/#volumes","title":"Volumes","text":"<ul> <li> <p>Provide persistent or temporary storage for Pods.</p> </li> <li> <p>Volume types include:</p> <ul> <li>emptyDir \u2013 Temporary storage shared between containers in a Pod.</li> <li>hostPath \u2013 Mounts a file or directory from the host node.</li> <li>persistentVolumeClaim (PVC) \u2013 Abstraction for durable storage, often backed by cloud storage solutions.</li> <li>configMap/secret \u2013 Mount configuration or secret data as files.</li> <li>nfs, csi, awsElasticBlockStore, etc. \u2013 Other network and cloud-specific storage options.</li> </ul> </li> </ul>"},{"location":"replicaset/","title":"ReplicaSet","text":""},{"location":"replicaset/#problem","title":"Problem","text":"<p>If a pod is running a web application and the pod goes down, then users won't be able to access the data.</p> <p>Somone would need to log in and fix the problem, but this takes time.</p>"},{"location":"replicaset/#replicaset_1","title":"ReplicaSet","text":"<p>If a pod crashes, it will create a new pod automatically with a health check.</p> <p>A ReplicaSet can be used to scale the number of pods.</p> <p></p>"},{"location":"replicaset/#example-yaml","title":"Example YAML","text":"<p><code>vim sampleReplicaSet.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: frontend\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  # modify replicas according to your case\n  replicas: 3\n  selector:\n    matchLabels:\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        tier: frontend\n    spec:\n      containers:\n        - name: php-redis\n          image: gcr.io/google_samples/gb-frontend:v3\n</code></pre>"},{"location":"replicaset/#commands","title":"Commands","text":"<p>create replica: <pre><code>kubectl create -f sampleReplicaSet.yaml\n</code></pre></p> <p>update replica: <pre><code>kubectl apply -f sampleReplicaSet.yaml\n</code></pre></p> <p>get replica: <pre><code>kubectl get rs\n</code></pre></p> <p>get pods: <pre><code>kubectl get pod\n</code></pre></p> <p>scale replicas: <pre><code># not recomended in production\nkubectl scale --replicas=1 rs/frontend\n# frontend = replica name\n</code></pre></p> <p>edit live config: <pre><code># not recomended in production\nkubectl edit rs frontend\n</code></pre></p> <p>delete replica: <pre><code>kubectl delete rs frontend\n</code></pre></p>"},{"location":"secrets/","title":"Secrets","text":"<p>A Secret is an object that contains a small amount of sensitive data such as a password, a token, or a key.</p>"},{"location":"secrets/#base64-encoding-method","title":"Base64 Encoding Method","text":"<p>There is a way to encrypt a secret but thats outside the scope of this docs.</p> <p>Base64 Encoding Example</p> <p>You can use <code>base64</code> to encode and decode secrets for Kubernetes. Kubernetes stores secret data as base64-encoded strings, so any values you provide will be encoded automatically when you create a Secret.</p> <pre><code># Encode a string to base64\necho -n \"secretpass\" | base64\n# Output: c2VjcmV0cGFzcw==\n\n# Decode a base64 string\necho 'c2VjcmV0cGFzcw==' | base64 --decode\n# Output: secretpass\n</code></pre>"},{"location":"secrets/#create-secret-imperative","title":"Create Secret | Imperative","text":"<pre><code>kubectl create secret generic db-secret --from-literal=MYSQL_ROOT_PASSWORD=somecomplexpassword\n# Output: secret/db-secret created\n</code></pre>"},{"location":"secrets/#create-secret-from-files","title":"Create Secret from Files","text":"<pre><code># Create files needed for rest of example.\necho -n 'admin' &gt; ./username.txt\necho -n '1f2d1e2e67df' &gt; ./password.txt\n\nkubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt\n</code></pre>"},{"location":"secrets/#view-secret","title":"View Secret","text":"<pre><code>$ kubectl get secret db-secret -o yaml\napiVersion: v1\ndata:\n  MYSQL_ROOT_PASSWORD: c29tZWNvbXBsZXhwYXNzd29yZA==\nkind: Secret\nmetadata:\n  ...\n</code></pre>"},{"location":"secrets/#create-secret-declarative","title":"Create Secret | Declarative","text":"<p>First, encode your secret value using base64:</p> <pre><code>echo -n \"somecomplexpassword\" | base64\n# Output: c29tZWNvbXBsZXhwYXNzd29yZA==\n</code></pre> <p>Then create a YAML file (e.g., <code>db-secret.yml</code>):</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ntype: Opaque\ndata:\n  my_root_pass: c29tZWNvbXBsZXhwYXNzd29yZA==\n</code></pre>"},{"location":"secrets/#pod-reading-secret","title":"POD Reading Secret","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      envFrom:\n        - secretRef:\n            name: db-secret\n</code></pre>"},{"location":"secrets/#pod-reading-specific-secret-key","title":"POD Reading Specific Secret Key","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: db-pod\n  labels:\n    app: db\n    project: infinity\nspec:\n  containers:\n    - name: mysql-container\n      image: mysql:5.7\n      env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: my_root_pass\n</code></pre>"},{"location":"secrets/#docker-config-secrets","title":"Docker config Secrets","text":"<p>Create Docker secret</p> <pre><code>kubectl create secret docker-registry secret-tiger-docker \\\n  --docker-email=tiger@acme.example \\\n  --docker-username=tiger \\\n  --docker-password=pass1234 \\\n  --docker-server=my-registry.example:5000\n</code></pre> <p>This command creates a Secret of type kubernetes.io/dockerconfigjson</p> <p>Retrieve the .data.dockerconfigjson field from that new Secret and decode the data:</p> <pre><code>kubectl get secret secret-tiger-docker -o jsonpath='{.data.*}' | base64 -d\n</code></pre> <p>Output</p> <pre><code>{\n  \"auths\": {\n    \"my-registry.example:5000\": {\n      \"username\": \"tiger\",\n      \"password\": \"pass1234\",\n      \"email\": \"tiger@acme.example\",\n      \"auth\": \"dGlnZXI6cGFzczEyMzQ=\"\n    }\n  }\n</code></pre> <p>Create a Pod that uses your Secret</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: private-reg\nspec:\n  containers:\n  - name: private-reg-container\n    image: &lt;your-private-image&gt;\n  imagePullSecrets:\n  - name: secret-tiger-docker\n</code></pre>"},{"location":"secrets/#hands-on","title":"Hands On","text":"<pre><code>echo -n \"admin\" | base64\n\necho -n \"mysecretpass\" | base 64\n\nvim mysecret.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ndata:\n  username: YWRtaW4=\n  password: bXlzZWNyZXRwYXNz\ntype: Opaque\n</code></pre> <p>VULNERABILITY: hardcoded-credentials Embedding credentials in source code risks unauthorized access</p> <p><pre><code>kubectl create -f mysecret.yaml\n# secret/mysecret created\n</code></pre> <pre><code>vim readsecret.yaml\n</code></pre></p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secret-env-pod\nspec:\n  containers:\n    - name: mycontainer\n      image: redis\n      env:\n        - name: SECRET_USERNAME\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: username\n              optional: false  # same as default; \"mysecret\" must exist and include a key named \"username\"\n        - name: SECRET_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysecret\n              key: password\n              optional: false  # same as default; \"mysecret\" must exist and include a key named \"password\"\n  restartPolicy: Never\n</code></pre> <pre><code>kubectl create -f readsecret.yaml\n# secret/mysecret created\n</code></pre> <pre><code>kubectl get pod\n</code></pre> <pre><code># OUTPUT\nNAME                 READY   STATUS    RESTARTS   AGE\nsecret-env-pod       1/1     Running   0          24s\n</code></pre> <pre><code>kubectl exec --stdin --tty secret-env-pod -- /bin/bash\nroot@secret-env-pod:data# echo $SECRET_USERNAME\nadmin\nroot@secret-env-pod:data# echo $SECRET_PASSWORD\nmysecretpass\n</code></pre>"},{"location":"service/","title":"Service","text":""},{"location":"service/#host-service-in-kubernetes","title":"Host Service In Kubernetes","text":"<ul> <li>If you want to expose the application running inside a pod as a network service then you will need to host a service</li> <li>Similar to load balancers</li> </ul>"},{"location":"service/#info","title":"Info","text":"<p>Kubernetes Pods are mortal. They are born and when they die they are not resurrected. If you use a Deployment to run your app, it can destroy and create Pods dynamically.</p> <p>Each Pod gets its own IP address, however the set of Pods running in one moment in time could be different from the set of Pods running that application a moment later.</p> <p>This leads to a problem: if some set of Pods(call them backenders) have functionality to other set of Pods(call them frontenders) inside your cluster, how do the frontenders find out keep track of which IP address to connect to, so that the frontend can use the backend part of the workload?</p> <p>Enter Services.</p>"},{"location":"service/#service-commands","title":"Service Commands","text":"<p>Create <pre><code>kubectl create -f service-defs.yml\n</code></pre></p> <p>Get info <pre><code>kubectl get svc\n</code></pre></p> <p>Delete <pre><code>kubectl delete svc &lt;service name&gt;\n</code></pre></p>"},{"location":"service/#services","title":"Services","text":""},{"location":"service/#nodeport","title":"NodePort","text":"<ul> <li>Similar to Port mapping in Docker</li> <li>A host port and map it to a container port</li> <li>Not for production</li> </ul> <p>Service example for the file <code>service-defs.yml</code>: <pre><code>apiVersion: v1\nkind: Service\n  name: webapp-service\nspec:\n  type: NodePort #  &lt;-- Service\n  ports:\n  - targetPort: 80\n    port: 80\n    nodePort: 30005\n    protocol: TCP\n  selector:\n    app: frontend # &lt;-- This is a Pod label\n</code></pre></p>"},{"location":"service/#example","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vproapp\n  labels:\n    app: vproapp\nspec:\n  containers:\n    - name: appcontainer\n      image: imranvisualpath/freshtomapp:V7\n      ports:\n        - name: vproapp-port\n          containerPort: 8080\n</code></pre> <p>NodePort Service <code>`vproapp-nodeport.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: helloworld-service\nspec:\n  ports:\n  - port: 8090\n    nodePort: 30001\n    targetPort: vproapp-port\n    protocol: TCP\n  selector:\n    app: vproapp\n  type: NodePort\n</code></pre> <pre><code>kubectl create -f vproapp-nodeport.yaml\n</code></pre> <pre><code>kubectl get svc\nkubectl describe svc &lt;nodeport-service-name&gt;\n</code></pre> <p>output example <pre><code>IP: 200.20.200.200 &lt;-- static ip of your service\nEndpoints: 100.10.1.1:8080 &lt;-- your pod ip\n</code></pre></p> <pre><code>svc describe pod | grep IP\n</code></pre> <p>Output will show same ip as on <code>endpoints</code> config value.</p> <p>To access the TomApp Application use the IP adress of either master or any worker nodes <pre><code>curl 200.20.200.200:30001\n</code></pre></p>"},{"location":"service/#loadbalancer","title":"LoadBalancer","text":"<ul> <li>Expose to outside network for production usecases.</li> </ul>"},{"location":"service/#example_1","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: vproapp\n  labels:\n    app: vproapp\nspec:\n  containers:\n    - name: appcontainer\n      image: imranvisualpath/freshtomapp:V7\n      ports:\n        - name: vproapp-port\n          containerPort: 8080\n</code></pre> <p>NodePort Service <code>`vproapp-nodebalancer.yml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: helloworld-service\nspec:\n  ports:\n  - port: 80\n    targetPort: vproapp-port\n    protocol: TCP\n  selector:\n    app: vproapp\n  type: LoadBalancer\n</code></pre> <p>To access the TomApp Application use the IP adress of either master or any worker nodes</p> <pre><code>curl 200.20.200.200\n</code></pre>"},{"location":"service/#clusterip","title":"ClusterIP","text":"<ul> <li>Internal network communication between pods.</li> <li>Example: Tomcat connecting to MySQL</li> </ul>"},{"location":"service/#example_2","title":"Example","text":"<p>Pod reference <code>vproapppod.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\n  labels:\n    app: backend\n    project: infinity\nspec:\n  containers:\n    - name: tomcat-container\n      image: tomcat\n      ports:\n        - name: app-port\n          containerPort: 8080\n</code></pre> <p>ClusterIP Service<code>tom-svc-clusterip.yml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\nspec:\n  type: ClusterIP\n  ports:\n    - targetPort: 8080\n      port: 8080\n      protocol: TCP\n  selector:\n    app: backend\n</code></pre>"},{"location":"setup_kops/","title":"Setup Kubernetes with Kops","text":""},{"location":"setup_kops/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> <li>kubectl installed</li> <li>Registered domain (e.g., from Namecheap)</li> <li>A subdomain configured via AWS Route 53 with 4 NS (Name Server) records</li> </ul>"},{"location":"setup_kops/#launch-ec2-instance","title":"\u2601\ufe0f Launch EC2 Instance","text":"<ul> <li>Name: <code>kops</code></li> <li>AMI (Amazon Machine Image): <code>Ubuntu Server 24.04 LTS</code> (but its recomended to use 22.04 as its stable)</li> <li>Instance type: <code>t2.micro</code></li> <li>Key pair: <code>Name: 'kopskey'</code>, <code>Key pair type: 'RSA'</code>, <code>Private key file format: '.pem'</code></li> <li>Security group: <code>Name: 'kops-sg'</code>, <code>Inbound rules: SSH from My IP}</code></li> </ul>"},{"location":"setup_kops/#create-iam-user","title":"\ud83d\udc64 Create IAM User","text":"<ul> <li>Name: <code>kopsadmin</code></li> <li>Permissions: <code>Attach policies directly -&gt; AdministratorAccess</code></li> </ul>"},{"location":"setup_kops/#create-access-key","title":"\ud83d\udd10 Create Access key","text":"<ul> <li>Choose Command Line Interface (CLI)</li> <li>Copy the Access Key ID and Secret Access Key</li> </ul>"},{"location":"setup_kops/#connect-to-ec2-instance","title":"\ud83d\udd11 Connect to EC2 Instance","text":"<pre><code>chmod 600 kopskey.pem\nssh -i kopskey.pem ubuntu@@&lt;your_ec2_public_ip&gt;\n</code></pre> <p>Update and install AWS CLI: <pre><code>sudo apt update\nsudo snap install aws-cli --classic\n</code></pre></p> <p>Configure AWS CLI: <pre><code>aws configure\n</code></pre> <pre><code>AWS Access Key ID [None]: *********************\nAWS Secret Key [None]: **************************\nDefault region name [None]: us-east-1\nDefault output format [None]: json\n</code></pre></p>"},{"location":"setup_kops/#generate-ssh-keys","title":"\ud83d\udd10 Generate SSH keys","text":"<pre><code>ssh-keygen\nls ~/.ssh\n# output authorized_keys id_ed25519 id_ed25519.pub\n</code></pre>"},{"location":"setup_kops/#install-kops","title":"\ud83d\udee0\ufe0f Install Kops","text":"<pre><code>curl -Lo kops https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '\"' -f 4)/kops-linux-amd64\n\nchmod +x kops\n\nsudo mv kops /usr/local/bin/kops\n</code></pre>"},{"location":"setup_kops/#install-kubectl","title":"\ud83e\uddf0 Install kubectl","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# check if installed\nkubectl version --client\n</code></pre>"},{"location":"setup_kops/#create-a-bucket-with-amazon-s3","title":"\ud83e\udea3 Create a bucket with Amazon S3","text":"<p>In the AWS Console or CLI:</p> <ul> <li>Bucket type: <code>General purpose</code></li> <li>Bucket name: <code>kopsstate1877</code> &lt;= This needs to be uniqe</li> </ul>"},{"location":"setup_kops/#create-the-dns-zone-with-amazon-route-53","title":"\ud83c\udf10 Create the DNS Zone with Amazon <code>Route 53</code>","text":"<p>Using example domain: alexanderlindholm.net</p> <ol> <li> <p>Go to Route 53 &gt; Hosted Zones</p> </li> <li> <p>Create a Public Hosted Zone:</p> </li> </ol> <p>domain name: <code>kubevpro.alexanderlindholm.net</code></p> <p>Type: <code>Public hosted zone</code></p>"},{"location":"setup_kops/#copy-ns-records","title":"\ud83e\uddfe Copy NS Records","text":"<ol> <li> <p>Click into your new hosted zone</p> </li> <li> <p>Under Records, copy the 4 NS records (e.g., ns-xxx.awsdns-xx.com)</p> </li> </ol>"},{"location":"setup_kops/#update-dns-records-in-namecheap","title":"\ud83d\udd17 Update DNS Records in Namecheap","text":"<p>In your domain provider\u2019s dashboard, add:</p> Type Host Value TTL NS Record kubevpro ns-xxx.awsdns-xx.com Automatic NS Record kubevpro ns-xxxx.awsdns-xx.org Automatic NS Record kubevpro ns-xxx.awsdns-xx.net Automatic NS Record kubevpro ns-xxxx.awsdns-xx.uk Automatic <p>replace Value column with the 4 NS Type Records from AWS Route 53</p>"},{"location":"setup_kops/#create-your-kubernetes-cluster","title":"\ud83d\ude80 Create Your Kubernetes Cluster","text":"<pre><code>kops create cluster \\\n  --name=kubevpro.alexanderlindholm.net \\\n  --state=s3://kopsstate1877 \\\n  --zones=us-east-1a,us-east-1b \\\n  --node-count=2 \\\n  --node-size=t3.small \\\n  --control-plane-size=t3.medium \\\n  --dns-zone=kubevpro.alexanderlindholm.net \\\n  --node-volume-size=12 \\\n  --control-plane-volume-size=12 \\\n  --ssh-public-key ~/.ssh/id_ed25519.pub\n</code></pre> <p>Apply the configuration: <pre><code>kops update cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877 --yes --admin\n</code></pre></p>"},{"location":"setup_kops/#validate-the-cluster","title":"\u2705 Validate the Cluster","text":"<pre><code>kops validate cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n</code></pre>"},{"location":"setup_kops/#useful-commandskube","title":"\ud83d\udd0d Useful CommandsKube","text":"<p>Get kubeconfig: <pre><code>cat .kube/config\n# config is created by master node\n</code></pre></p> <p>List nodes: <pre><code>kubectl get nodes\n</code></pre></p>"},{"location":"setup_kops/#delete-the-cluster","title":"\ud83d\uddd1\ufe0f Delete the Cluster","text":"<pre><code>kops delete cluster --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877 --yes\n</code></pre> <p>Then power off or delete the EC2 instance (Kops)</p>"},{"location":"setup_kops/#troubleshoot","title":"\u26a0\ufe0f Troubleshoot","text":"<p>List instance groups: <pre><code>kops get ig --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n\n# Output Example:\n# NAME              ROLE        MACHINETYPE MIN MAX ZONES\n# control-plane-us-east-1a  ControlPlane    t3.medium   1   1   us-east-1a\n# nodes-us-east-1a      Node        t3.small    1   1   us-east-1a\n# nodes-us-east-1b      Node        t3.small    1   1   us-east-1b\n</code></pre></p> <p>Edit an instance group (e.g., if an AMI is invalid): <pre><code>kops edit ig nodes-us-east-1a --name=kubevpro.alexanderlindholm.net --state=s3://kopsstate1877\n</code></pre></p> <p>\ud83c\udf10 Verify DNS <pre><code>dig +short api.kubevpro.alexanderlindholm.net\n# output example: \n# 5.34.68.27\n</code></pre></p> <p>You should see this IP listed in Route 53 &gt; Hosted Zones under A or CNAME record for your subdomain.</p>"},{"location":"setup_kubectl/","title":"Kubectl","text":""},{"location":"setup_kubectl/#system-requirements","title":"\ud83d\udccb System Requirements","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> </ul>"},{"location":"setup_kubectl/#install-kubectl-binary","title":"\ud83d\udd27 Install <code>kubectl</code> binary","text":"<p>Based on the official kubectl documentation</p>"},{"location":"setup_kubectl/#download-the-latest-release","title":"\ud83d\udce5 Download the Latest Release","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre>"},{"location":"setup_kubectl/#validate-the-binary","title":"\u2705 Validate the Binary","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256\"\n\necho \"$(cat kubectl.sha256)  kubectl\" | sha256sum --check\n\n# If valid, the output should be: \"kubectl: OK\"\n# If not, it will say: \"kubectl: FAILED\"\n</code></pre>"},{"location":"setup_kubectl/#install-kubectl","title":"\ud83d\udee0 Install kubectl","text":"<pre><code>sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"setup_minikube/","title":"Setup Local Test Enviroment with Minikube","text":""},{"location":"setup_minikube/#system-requirements","title":"\ud83d\udccb System Requirements","text":"<ul> <li>\ud83d\udc27 Linux-based OS</li> <li>Docker or a compatible VM hypervisor (e.g., VirtualBox, Hyper-V)</li> <li>kubectl installed</li> </ul>"},{"location":"setup_minikube/#install-binary-minikube","title":"\ud83d\udce6 Install Binary Minikube","text":"<p>This is a copy of the official install docs</p>"},{"location":"setup_minikube/#binary-installation","title":"\ud83d\udd27 Binary Installation","text":"<pre><code>curl -LO https://github.com/kubernetes/minikube/releases/latest/download/minikube-linux-amd64\n\nsudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64\n</code></pre>"},{"location":"setup_minikube/#start-your-cluster","title":"\ud83d\udfe2 Start your cluster","text":"<pre><code>minikube start\n</code></pre>"},{"location":"setup_minikube/#interact-with-your-cluster","title":"\ud83d\udce1 Interact with your cluster","text":"<pre><code>kubectl get po -A\n</code></pre> <p>Or</p> <pre><code>minikube kubectl -- get po -A\n</code></pre>"},{"location":"setup_minikube/#deploy-dashboard","title":"\ud83d\udda5\ufe0f Deploy dashboard","text":"<pre><code>minikube dashboard\n</code></pre>"},{"location":"setup_minikube/#get-nodes","title":"\ud83e\uddf1 Get Nodes","text":"<pre><code>kubectl get nodes\n</code></pre>"},{"location":"setup_minikube/#deploy-a-test-application","title":"\ud83d\udce6 Deploy a Test Application","text":"<pre><code>kubectl create deployment hello-minikube --image=kicbase/echo-server:1.0\n\nkubectl expose deployment hello-minikube --type=NodePort --port=8080\n\n# Display service\nkubectl get services hello-minikube\n\n# Access this service by letting minkube launch a web browser for you\nminikube service hello-minikube\n\n# Alternativly enable port forwarding\nkubectl port-forward service/hello-minikube 7080:8080\n</code></pre>"},{"location":"setup_minikube/#delete-cluster-resources","title":"\u274c Delete Cluster &amp; Resources","text":"<pre><code>kubectl get svc\nkubectl delete svc hello-minikube\n\nkubectl get deploy\nkubectl delete deploy hello-minikube\n\nminikube stop\nminikube delete\n</code></pre>"},{"location":"setup_minikube/#commands-to-manage-your-cluster","title":"\ud83d\udee0 Commands to Manage Your Cluster","text":"<pre><code>minikube pause                                      # Pause Kubernetes without impacting deployed applications\n\nminikube unpause                                    # Unpause a paused instance\n\nminikube stop                                       # Halt the cluster\n\nminikube config set memory 9001                     # Change the default memory limit (requires a restart)\n\nminikube addons list                                # minikube addons list\n\nminikube start -p aged --kubernetes-version=v1.16.1 # Create a second cluster running an older Kubernetes release\n\nminikube delete --all                               # Delete all of the minikube clusters\n</code></pre>"},{"location":"taints_tolerations/","title":"Taints and Tolerations","text":""},{"location":"taints_tolerations/#taints-and-toleration","title":"Taints and Toleration","text":"<p>Only allows specific pods with the required tolerations (key-value pairs) to be scheduled on nodes that have matching taints.</p>"},{"location":"volumes/","title":"Volumes","text":""},{"location":"volumes/#type-of-volumes","title":"Type of Volumes","text":"<ul> <li>awsElasticBlockStore</li> <li>azureDisk</li> <li>cephhfs</li> <li>cinder</li> <li>fc (fibre chanel)</li> <li>flocker (depricated)</li> <li>gcePersistentDisk (for Google Cloud)</li> <li>glusterfs (RedHat)</li> <li>iscsi</li> <li>local</li> <li>NFS</li> <li>portworxVolume</li> <li>vSphere VMDK</li> <li>hostPath (not recomended for production)</li> </ul>"},{"location":"volumes/#hostpath-configuration-example","title":"hostPath configuration example","text":"<pre><code>---\n# This manifest mounts /data/foo on the host as /foo inside the\n# single container that runs within the hostpath-example-linux Pod.\n#\n# The mount into the container is read-only.\napiVersion: v1\nkind: Pod\nmetadata:\n  name: hostpath-example-linux\nspec:\n  os: { name: linux }\n  nodeSelector:\n    kubernetes.io/os: linux\n  containers:\n  - name: example-container\n    image: registry.k8s.io/test-webserver\n    volumeMounts:\n    - mountPath: /foo # &lt;-- container volume\n      name: example-volume \n      readOnly: true\n  volumes:\n  - name: example-volume\n    # mount /data/foo, but only if that directory already exists\n    hostPath:\n      path: /data/foo # directory location on host\n      type: Directory # this field is optional\n</code></pre>"},{"location":"volumes/#hands-on","title":"Hands on","text":"<pre><code>vim mysqlpod.yaml\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: dbpod\nspec:\n  os: { name: linux }\n  nodeSelector:\n    kubernetes.io/os: linux\n  containers:\n  - name: mysql\n    image: mysql:5.7\n    volumeMounts:\n    - mountPath: /var/lib/mysql # &lt;-- container volume\n      name: dbvol\n      readOnly: true\n  volumes:\n  - name: dbvol\n    hostPath:\n      path: /data\n      type: DirectoryOrCreate\n</code></pre> <pre><code>kubectl apply -f mysqlpod.yaml\n\nkubectl get pods\n\nkubectl describe dbpod\n\nkubectl delete pod dbpod\n</code></pre> <p>validate that volume host path is <code>/data</code></p> <p>validate that mount volume is <code>/var/lib/mysql</code></p>"}]}